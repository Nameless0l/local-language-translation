{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP : 57 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 58 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 59 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 60 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 61 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 62 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 63 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 64 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 65 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 66 / 85...\n",
      "witdh = 595\n",
      "height = 842\n",
      "STEP : 67 / 85...\n",
      "witdh = 595\n",
      "height = 842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m             output[j] \u001b[39m=\u001b[39m output[j]\u001b[39m.\u001b[39mreplace(output[j][index1:index2\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m         index1 \u001b[39m=\u001b[39m output[j]\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39m(\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(output)):\n\u001b[0;32m     36\u001b[0m     semi_colon \u001b[39m=\u001b[39m output[j][::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pdf = pdfplumber.open(\"./dcos_eton.pdf\")\n",
    "\n",
    "crop_coord_left = [0, 50, 210, 550]\n",
    "crop_coord_right = [210, 50, 420, 550]\n",
    "skip_words = ['prép.', 'adv.', 'n.', 'Cl:', '3a/6', 'Litt', 'Voir:']\n",
    "accents = ['ə́ ', 'b́']\n",
    "with open(\"text.txt\", mode=\"w\", encoding='utf-8') as text_out:\n",
    "    for i in range(285, 369):\n",
    "        print(f\"STEP : {i} / 370...\")\n",
    "        my_bbox_left = (crop_coord_left[0], crop_coord_left[1], crop_coord_left[2], crop_coord_left[3])\n",
    "        my_bbox_right = (crop_coord_right[0], crop_coord_right[1], crop_coord_right[2], crop_coord_right[3])\n",
    "\n",
    "        page_crop_left = pdf.pages[i].crop(bbox=my_bbox_left)\n",
    "        page_words = page_crop_left.filter(lambda obj : obj[\"object_type\"] == \"char\" and (\"Italic\" not in obj[\"fontname\"] or (\"Italic\" in obj[\"fontname\"] and obj[\"text\"] == \";\"))).extract_text().split()\n",
    "        page_keywords = page_crop_left.filter(lambda obj : obj[\"object_type\"] == \"char\" and (\"Bold\" in obj[\"fontname\"] or (\"Italic\" in obj[\"fontname\"] and obj[\"text\"] == \";\"))).extract_text()\n",
    "        \n",
    "        output = []\n",
    "        text = \" \".join(page_words)\n",
    "        for chunk in text.split('. '):\n",
    "            for c in chunk.split('.́ '):\n",
    "                output.extend(c.split('.'))\n",
    "        \n",
    "        for j in range(len(output)):\n",
    "            index1 = output[j].find(\"(\")\n",
    "            while index1 != -1:\n",
    "                index2 = output[j].find(\")\")\n",
    "                if index2 == -1:\n",
    "                    # output[j] = output[j][:len(output[j]) - 1] + output[j + 1]\n",
    "                    # del output[j + 1]\n",
    "                    break\n",
    "                else:\n",
    "                    output[j] = output[j].replace(output[j][index1:index2+1], '')\n",
    "                index1 = output[j].find(\"(\")\n",
    "\n",
    "        for j in range(len(output)):\n",
    "            semi_colon = output[j][::-1].find(';')\n",
    "\n",
    "            if semi_colon != -1:\n",
    "                meanings = []\n",
    "                while semi_colon !=  -1:\n",
    "                    output[j] = output[j][:len(output[j])-semi_colon - 1]\n",
    "                    semi_colon = output[j][::-1].find(';')\n",
    "\n",
    "                last2 = output[j].split()\n",
    "                try:\n",
    "                    meanings.append(last2[1])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                for meaning in meanings:\n",
    "                    text_out.write(f'{last2[0]} {meaning}\\n')\n",
    "            else:\n",
    "                text_out.write(f'{output[j]}\\n')\n",
    "\n",
    "\n",
    "        page_crop_right = pdf.pages[i].crop(bbox=my_bbox_right)\n",
    "        page_words = page_crop_right.filter(lambda obj : obj[\"object_type\"] == \"char\" and (\"Italic\" not in obj[\"fontname\"] or (\"Italic\" in obj[\"fontname\"] and obj[\"text\"] == \";\"))).extract_text().split()\n",
    "        page_keywords = page_crop_right.filter(lambda obj : obj[\"object_type\"] == \"char\" and (\"Bold\" in obj[\"fontname\"] or (\"Italic\" in obj[\"fontname\"] and obj[\"text\"] == \";\"))).extract_text()\n",
    "\n",
    "        output = []\n",
    "        text = \" \".join(page_words)\n",
    "        for chunk in text.split('. '):\n",
    "            for c in chunk.split('.́ '):\n",
    "                output.extend(c.split('.'))\n",
    "        \n",
    "        for j in range(len(output)):\n",
    "            for k in range(11):\n",
    "                if f'({k})' in output[j]:\n",
    "                    output[j] = output[j].replace(f'({k})', '') \n",
    "\n",
    "        for j in range(len(output)):\n",
    "            index1 = output[j].find(\"(\")\n",
    "            while index1 != -1:\n",
    "                index2 = output[j].find(\")\")\n",
    "                if index2 == -1:\n",
    "                    # output[j] = output[j][:len(output[j]) - 1] + output[j + 1]\n",
    "                    # del output[j + 1]\n",
    "                    break\n",
    "                else:\n",
    "                    output[j] = output[j].replace(output[j][index1:index2+1], '')\n",
    "                index1 = output[j].find(\"(\")\n",
    "\n",
    "        for j in range(len(output)):\n",
    "            semi_colon = output[j][::-1].find(';')\n",
    "\n",
    "            if semi_colon != -1:\n",
    "                meanings = []\n",
    "                while semi_colon !=  -1:\n",
    "                    meanings.append(output[j][len(output[j])-semi_colon:])\n",
    "                    output[j] = output[j][:len(output[j])-semi_colon - 1]\n",
    "                    semi_colon = output[j][::-1].find(';')\n",
    "\n",
    "                last2 = output[j].split()\n",
    "                try:\n",
    "                    meanings.append(last2[1])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                for meaning in meanings:\n",
    "                    text_out.write(f'{last2[0]} {meaning}\\n')\n",
    "            else:\n",
    "                text_out.write(f'{output[j]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "with open('text.txt', mode='r', encoding='utf-8') as data_in:\n",
    "    data = data_in.readlines()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            if data[i] == '\\n':\n",
    "                del data[i]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    with open('out.txt', mode='w', encoding='utf-8') as data_out:\n",
    "        for line in data:\n",
    "            data_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "with open('out.txt', mode='r', encoding='utf-8') as data_in:\n",
    "    data = data_in.readlines()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            data_split = data[i].split()\n",
    "            if len(data_split) == 1:\n",
    "                del data[i]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    with open('outo.txt', mode='w', encoding='utf-8') as data_out:\n",
    "        for line in data:\n",
    "            data_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "letters_lower = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"k\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\", 'à']\n",
    "letters_cap = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "with open('outo.txt', mode='r', encoding='utf-8') as data_in:\n",
    "    data = data_in.readlines()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            if data[i][0] not in letters_lower and data[i][0] not in letters_cap:\n",
    "                data[i] = data[i][2:]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    with open('outoo.txt', mode='w', encoding='utf-8') as data_out:\n",
    "        for line in data:\n",
    "            data_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\","
     ]
    }
   ],
   "source": [
    "for i in range(97, 97+26):\n",
    "    print(f'\"{chr(i)}\"'.upper(), end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "with open('outoo.txt', mode='r', encoding='utf-8') as data_in:\n",
    "    data = data_in.readlines()\n",
    "    data.sort(key=len)\n",
    "\n",
    "    with open('outoooo.txt', mode='w', encoding='utf-8') as data_out:\n",
    "        for line in data:\n",
    "            data_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#postprocess\n",
    "with open('Eton_No_preprocess4.txt', mode='r', encoding='utf-8') as data_in:\n",
    "    with open('Eton_preprocess.txt', mode='a', encoding='utf-8') as data_out:\n",
    "        with open('Eton_No_preprocess5.txt', mode='w', encoding='utf-8') as data_out1:\n",
    "            data = data_in.readlines()\n",
    "            for line in data:\n",
    "                line_split = line.split(' ')\n",
    "                if len(line_split) == 2:\n",
    "                    data_out.write(f'{line_split[0]}\\t{line_split[1]}')       \n",
    "                else:\n",
    "                    if ('ə ́' in line or 'ɔ ́' in line or 'ə ̀' in line or 'ə ̂' in line) and len(line_split) == 3:\n",
    "                        data_out.write(f'{line_split[0]}\\t{line_split[1]} {line_split[2]}')\n",
    "                    else:\n",
    "                        data_out1.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39;49m\u001b[39msÿæl\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin-1\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "data = 'UTF-8 data'\n",
    "udata = data.decode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67e0cbc25fa4f5baaacba1240f401bc655b640f8e15cfc935dfee2e63491bdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
